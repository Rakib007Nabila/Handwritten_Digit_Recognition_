# -*- coding: utf-8 -*-
"""Handwritten Digit Recognition_using Neural Network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Vd0IKcgNeuOjMWvfm0dN6Mv3tMTMlKvd

# Install Required Libraries
"""

!pip install scipy

"""# Import Libraries"""

import numpy as np
import scipy.io
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

"""# Load the Dataset (.mat File)"""

from google.colab import files

#uploaded = files.upload()  # Upload your .mat file manually

data = scipy.io.loadmat("/content/mnist-original.mat")

"""# Display the Dataset"""

import scipy.io
import numpy as np
import matplotlib.pyplot as plt

# Load the dataset
data = scipy.io.loadmat("/content/mnist-original.mat")

# Extract features (images) and labels
X = data["data"].T  # Transpose to get (samples, features)
y = data["label"][0]  # Labels are stored in a row vector

# Print dataset shapes
print(f"Shape of X (images): {X.shape}")  # (70000, 784) → 70,000 images of 28x28 pixels
print(f"Shape of y (labels): {y.shape}")  # (70000,) → 70,000 labels

# Display the last 20 labels
print("\nLast 20 labels:", y[:20])

# Reshape and visualize the last 20 images
fig, axes = plt.subplots(4, 5, figsize=(10, 8))  # 4 rows, 5 columns

for i, ax in enumerate(axes.flat):
    img_index = 20 + i  # Get the last 20 images from the dataset
    ax.imshow(X[img_index].reshape(28, 28), cmap="gray")  # Reshape 784 features into 28x28
    ax.set_title(f"Label: {int(y[img_index])}")
    ax.axis("off")

plt.tight_layout()
plt.show()

# Display the last 20 labels
print("\nLast 20 labels:", y[-20:])

# Reshape and visualize the last 20 images
fig, axes = plt.subplots(4, 5, figsize=(10, 8))  # 4 rows, 5 columns

for i, ax in enumerate(axes.flat):
    img_index = -20 + i  # Get the last 20 images from the dataset
    ax.imshow(X[img_index].reshape(28, 28), cmap="gray")  # Reshape 784 features into 28x28
    ax.set_title(f"Label: {int(y[img_index])}")
    ax.axis("off")

plt.tight_layout()
plt.show()

"""# Extract Features and Labels"""

X = data['data']  # Feature matrix
X = X.transpose()
y = data['label']  # Labels
y = y.flatten()

# Convert labels to categorical format (One-hot encoding)
y = tf.keras.utils.to_categorical(y, num_classes=10)

# Normalize the pixel values (assuming grayscale images)
X = X / 255.0

# Reshape to match TensorFlow input requirements (Flattening might not be needed)
X = X.reshape(X.shape[0], 28, 28, 1)

"""# Split Data into Training and Testing Sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Define the Neural Network Model"""

model = Sequential([
    Flatten(input_shape=(28, 28, 1)),  # Flatten image to 1D
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(10, activation='softmax')  # 10 output classes (digits 0-9)
])

"""# Compile the Model"""

model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

"""# Train the Model"""

history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

"""# Evaluate the Model"""

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc * 100:.2f}%")

"""# Visualize Accuracy and Loss"""

plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Test Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""# Test on a New Image"""

def predict_sample(index):
    sample = X_test[index].reshape(1, 28, 28, 1)
    prediction = np.argmax(model.predict(sample))

    plt.imshow(X_test[index].reshape(28, 28), cmap='gray')
    plt.title(f"Predicted: {prediction}")
    plt.show()

predict_sample(197)  # Change index to test different images

"""# Save the model"""

model.save("handwritten_digit_model.h5")